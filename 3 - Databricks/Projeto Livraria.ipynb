{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edd05861-8335-4ff1-8449-e8f94da28561",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS TB_LIVRO_AUTOR;\n",
    "DROP TABLE IF EXISTS TB_AUTOR;\n",
    "DROP TABLE IF EXISTS TB_LIVRO;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0073d2b-29aa-46b0-9ef3-522630642f94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">res20: Boolean = false\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">res20: Boolean = false\n</div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs rm -r /user/hive/warehouse/tb_autor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea628fd8-36c5-48a0-bd6f-c47271314ee5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">res21: Boolean = false\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">res21: Boolean = false\n</div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs rm -r /user/hive/warehouse/tb_livro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90b3265f-3404-4cda-80ff-3a3742af98dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">res22: Boolean = false\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">res22: Boolean = false\n</div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs rm -r /user/hive/warehouse/tb_livro_autor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1ed8b43-8ba6-40d0-90c7-902183f990f1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Criação das tabelas TB_AUTOR,TB_LIVRO e a associativa TB_LIVRO_AUTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "965bdf8a-9176-45d5-ac9b-5535b05a052a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Tscrisql: String = CREATE OR REPLACE TABLE TB_AUTOR (ID_AUTOR DOUBLE,NOME STRING,SEXO STRING, DATA_NASCIMENTO STRING) USING DELTA ;\n",
       "Tscrisql1: String = CREATE OR REPLACE TABLE TB_LIVRO (ID_LIVRO DOUBLE,ISBN STRING,TITULO STRING,EDICAO DOUBLE,PRECO DOUBLE,QTDE_ESTOQUE DOUBLE) USING DELTA;\n",
       "Tscrisql3: String = CREATE OR REPLACE TABLE TB_LIVRO_AUTOR (ID_LIVRO_AUTOR DOUBLE,ID_LIVRO DOUBLE, ID_AUTOR DOUBLE) USING DELTA;\n",
       "res23: org.apache.spark.sql.DataFrame = []\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Tscrisql: String = CREATE OR REPLACE TABLE TB_AUTOR (ID_AUTOR DOUBLE,NOME STRING,SEXO STRING, DATA_NASCIMENTO STRING) USING DELTA ;\nTscrisql1: String = CREATE OR REPLACE TABLE TB_LIVRO (ID_LIVRO DOUBLE,ISBN STRING,TITULO STRING,EDICAO DOUBLE,PRECO DOUBLE,QTDE_ESTOQUE DOUBLE) USING DELTA;\nTscrisql3: String = CREATE OR REPLACE TABLE TB_LIVRO_AUTOR (ID_LIVRO_AUTOR DOUBLE,ID_LIVRO DOUBLE, ID_AUTOR DOUBLE) USING DELTA;\nres23: org.apache.spark.sql.DataFrame = []\n</div>",
       "datasetInfos": [
        {
         "name": "res23",
         "schema": {
          "fields": [],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "org.apache.spark.sql.DataFrame"
        }
       ],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "val Tscrisql = \"CREATE OR REPLACE TABLE TB_AUTOR (ID_AUTOR DOUBLE,NOME STRING,SEXO STRING, DATA_NASCIMENTO STRING) USING DELTA ;\"\n",
    "spark.sql(Tscrisql);\n",
    "\n",
    "val Tscrisql1 = \"CREATE OR REPLACE TABLE TB_LIVRO (ID_LIVRO DOUBLE,ISBN STRING,TITULO STRING,EDICAO DOUBLE,PRECO DOUBLE,QTDE_ESTOQUE DOUBLE) USING DELTA;\"\n",
    "spark.sql(Tscrisql1);\n",
    "\n",
    "val Tscrisql3 = \"CREATE OR REPLACE TABLE TB_LIVRO_AUTOR (ID_LIVRO_AUTOR DOUBLE,ID_LIVRO DOUBLE, ID_AUTOR DOUBLE) USING DELTA;\"\n",
    "spark.sql(Tscrisql3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ebd2514-26cc-4565-a76f-6d4c3dd6c8a9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####Verificar a propriedade da tabela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4d01433-2b38-42c6-a6fc-747bb858ccfd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>key</th><th>value</th></tr></thead><tbody><tr><td>Type</td><td>MANAGED</td></tr><tr><td>delta.minReaderVersion</td><td>1</td></tr><tr><td>delta.minWriterVersion</td><td>2</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Type",
         "MANAGED"
        ],
        [
         "delta.minReaderVersion",
         "1"
        ],
        [
         "delta.minWriterVersion",
         "2"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "key",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "value",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SHOW TBLPROPERTIES TB_AUTOR;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0839729b-2ca2-4be2-89d3-0159b80bc1cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Inserção de registros na tabela TB_AUTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80cc8180-2cc3-4d8f-82bb-ee11200462eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">scrisql: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (1,'Joao','M', '01/01/1970');\n",
       "scrisql1: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (2,'Maria','F', '25/11/1975');\n",
       "scrisql2: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (3,'Sandra','F', '14/11/1978');\n",
       "scrisql3: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (4,'Tereza','F', '21/11/1978');\n",
       "res25: org.apache.spark.sql.DataFrame = [num_affected_rows: bigint, num_inserted_rows: bigint]\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">scrisql: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (1,'Joao','M', '01/01/1970');\nscrisql1: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (2,'Maria','F', '25/11/1975');\nscrisql2: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (3,'Sandra','F', '14/11/1978');\nscrisql3: String = Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO) values (4,'Tereza','F', '21/11/1978');\nres25: org.apache.spark.sql.DataFrame = [num_affected_rows: bigint, num_inserted_rows: bigint]\n</div>",
       "datasetInfos": [
        {
         "name": "res25",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_inserted_rows",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "org.apache.spark.sql.DataFrame"
        }
       ],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "val scrisql = \"Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO)\"+\n",
    "\" values (1,'Joao','M', '01/01/1970');\"\n",
    "spark.sql(scrisql);\n",
    "\n",
    "val scrisql1 = \"Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO)\"+\n",
    "\" values (2,'Maria','F', '25/11/1975');\"\n",
    "spark.sql(scrisql1);\n",
    "\n",
    "val scrisql2 = \"Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO)\"+\n",
    "\" values (3,'Sandra','F', '14/11/1978');\"\n",
    "spark.sql(scrisql2);\n",
    "\n",
    "val scrisql3 = \"Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO)\"+\n",
    "\" values (4,'Tereza','F', '21/11/1978');\"\n",
    "spark.sql(scrisql3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c77cae3f-3bd6-4d41-aa0a-26df371b5a48",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Inserção de registros na tabela TB_LIVRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c89b302-542d-4e45-aeb1-9fe69c24ca1c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Lscrisql: String = Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE)  values (1,'1234567890','Banco de Dados',2,10,407);\n",
       "Lscrisql1: String = Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE)  values (2,'2345678901','Redes de Computadores',1,10,60);\n",
       "Lscrisql2: String = Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE)  values (3,'3456789012','Interface Homem-Maquina',3,10,10);\n",
       "res27: org.apache.spark.sql.DataFrame = [num_affected_rows: bigint, num_inserted_rows: bigint]\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Lscrisql: String = Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE)  values (1,'1234567890','Banco de Dados',2,10,407);\nLscrisql1: String = Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE)  values (2,'2345678901','Redes de Computadores',1,10,60);\nLscrisql2: String = Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE)  values (3,'3456789012','Interface Homem-Maquina',3,10,10);\nres27: org.apache.spark.sql.DataFrame = [num_affected_rows: bigint, num_inserted_rows: bigint]\n</div>",
       "datasetInfos": [
        {
         "name": "res27",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_inserted_rows",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "org.apache.spark.sql.DataFrame"
        }
       ],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "val Lscrisql = \"Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE)\"+\n",
    "\"  values (1,'1234567890','Banco de Dados',2,10,407);\"\n",
    "spark.sql(Lscrisql);\n",
    "\n",
    "val Lscrisql1 = \"Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE)\"+\n",
    "\"  values (2,'2345678901','Redes de Computadores',1,10,60);\"\n",
    "spark.sql(Lscrisql1);\n",
    "\n",
    "val Lscrisql2 = \"Insert into TB_LIVRO (ID_LIVRO,ISBN,TITULO,EDICAO,PRECO,QTDE_ESTOQUE)\"+\n",
    "\"  values (3,'3456789012','Interface Homem-Maquina',3,10,10);\"\n",
    "spark.sql(Lscrisql2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4348010-39e4-4192-9042-d0d8302cee36",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Inserção de registros na tabela TB_LIVRO_AUTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db3227c5-7e35-4ade-8e66-3f6d8d4e2d6c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">LAscrisql: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (1,1,1);\n",
       "LAscrisql1: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (2,1,2);\n",
       "LAscrisql2: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (3,2,3);\n",
       "LAscrisql3: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (4,3,2);\n",
       "LAscrisql4: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (5,3,3);\n",
       "res29: org.apache.spark.sql.DataFrame = [num_affected_rows: bigint, num_inserted_rows: bigint]\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">LAscrisql: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (1,1,1);\nLAscrisql1: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (2,1,2);\nLAscrisql2: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (3,2,3);\nLAscrisql3: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (4,3,2);\nLAscrisql4: String = Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (5,3,3);\nres29: org.apache.spark.sql.DataFrame = [num_affected_rows: bigint, num_inserted_rows: bigint]\n</div>",
       "datasetInfos": [
        {
         "name": "res29",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "num_affected_rows",
            "nullable": true,
            "type": "long"
           },
           {
            "metadata": {},
            "name": "num_inserted_rows",
            "nullable": true,
            "type": "long"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "org.apache.spark.sql.DataFrame"
        }
       ],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "val LAscrisql = \"Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (1,1,1);\"\n",
    "spark.sql(LAscrisql);\n",
    "\n",
    "val LAscrisql1 = \"Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (2,1,2);\"\n",
    "spark.sql(LAscrisql1);\n",
    "\n",
    "val LAscrisql2 = \"Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (3,2,3);\"\n",
    "spark.sql(LAscrisql2);\n",
    "\n",
    "val LAscrisql3 = \"Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (4,3,2);\"\n",
    "spark.sql(LAscrisql3);\n",
    "\n",
    "val LAscrisql4 = \"Insert into TB_LIVRO_AUTOR (ID_LIVRO_AUTOR,ID_LIVRO,ID_AUTOR) values (5,3,3);\"\n",
    "spark.sql(LAscrisql4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ed4c247-41c2-4f70-8034-4523eb08ee93",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Selecionando os registros, ligando todas as tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19290aaf-080a-41bf-a808-36bbee92a8b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>TITULO</th><th>ISBN</th><th>PRECO</th><th>NOME</th><th>DATA_NASCIMENTO</th></tr></thead><tbody><tr><td>Interface Homem-Maquina</td><td>3456789012</td><td>10.0</td><td>Sandra</td><td>14/11/1978</td></tr><tr><td>Interface Homem-Maquina</td><td>3456789012</td><td>10.0</td><td>Maria</td><td>25/11/1975</td></tr><tr><td>Redes de Computadores</td><td>2345678901</td><td>10.0</td><td>Sandra</td><td>14/11/1978</td></tr><tr><td>Banco de Dados</td><td>1234567890</td><td>10.0</td><td>Maria</td><td>25/11/1975</td></tr><tr><td>Banco de Dados</td><td>1234567890</td><td>10.0</td><td>Joao</td><td>01/01/1970</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Interface Homem-Maquina",
         "3456789012",
         10.0,
         "Sandra",
         "14/11/1978"
        ],
        [
         "Interface Homem-Maquina",
         "3456789012",
         10.0,
         "Maria",
         "25/11/1975"
        ],
        [
         "Redes de Computadores",
         "2345678901",
         10.0,
         "Sandra",
         "14/11/1978"
        ],
        [
         "Banco de Dados",
         "1234567890",
         10.0,
         "Maria",
         "25/11/1975"
        ],
        [
         "Banco de Dados",
         "1234567890",
         10.0,
         "Joao",
         "01/01/1970"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "TITULO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ISBN",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "PRECO",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "NOME",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "DATA_NASCIMENTO",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT TB_LIVRO.TITULO,\n",
    "TB_LIVRO.ISBN,TB_LIVRO.PRECO,TB_AUTOR.NOME,TB_AUTOR.DATA_NASCIMENTO\n",
    "FROM TB_LIVRO\n",
    "INNER JOIN TB_LIVRO_AUTOR ON TB_LIVRO.ID_LIVRO =\n",
    "TB_LIVRO_AUTOR.ID_LIVRO\n",
    "INNER JOIN TB_AUTOR ON TB_AUTOR.ID_AUTOR = TB_LIVRO_AUTOR.ID_AUTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6146a66-af42-4e69-a9a8-356d62191b1a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Criando uma check constraints para a tabela TB_AUTOR, somente permitindo a inserção de 4 registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee4a6a14-48e9-4041-9759-bdee97be8017",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>key</th><th>value</th></tr></thead><tbody><tr><td>Type</td><td>MANAGED</td></tr><tr><td>delta.constraints.validids</td><td>ID_AUTOR > 0 and ID_AUTOR < 5</td></tr><tr><td>delta.minReaderVersion</td><td>1</td></tr><tr><td>delta.minWriterVersion</td><td>3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Type",
         "MANAGED"
        ],
        [
         "delta.constraints.validids",
         "ID_AUTOR > 0 and ID_AUTOR < 5"
        ],
        [
         "delta.minReaderVersion",
         "1"
        ],
        [
         "delta.minWriterVersion",
         "3"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "key",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "value",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "ALTER TABLE TB_AUTOR DROP CONSTRAINT validIds;\n",
    "ALTER TABLE TB_AUTOR ADD CONSTRAINT validIds CHECK (ID_AUTOR> 0 and ID_AUTOR < 5);\n",
    "SHOW TBLPROPERTIES TB_AUTOR;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a753cbe-f1fd-4aa5-82f2-5b5f7a21a944",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Verificando se a check constraints irá funcionar, executando um insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "423ff611-e302-47a6-9fa3-47b6ec67f4a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {
        "isDbfsCommandResult": false
       },
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"> - ID_AUTOR : 5.0\n",
       "\tat com.databricks.sql.transaction.tahoe.schema.InvariantViolationException$.apply(InvariantViolationException.scala:59)\n",
       "\tat com.databricks.sql.transaction.tahoe.schema.InvariantViolationException$.apply(InvariantViolationException.scala:69)\n",
       "\tat com.databricks.sql.transaction.tahoe.schema.InvariantViolationException.apply(InvariantViolationException.scala)\n",
       "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n",
       "\tat com.databricks.sql.transaction.tahoe.constraints.DeltaInvariantCheckerExec.$anonfun$doExecute$3(DeltaInvariantCheckerExec.scala:90)\n",
       "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:91)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:437)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1715)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:444)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$20(FileFormatWriter.scala:336)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n",
       "\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:156)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:125)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:95)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:832)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1681)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:835)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:690)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"> - ID_AUTOR : 5.0\n\tat com.databricks.sql.transaction.tahoe.schema.InvariantViolationException$.apply(InvariantViolationException.scala:59)\n\tat com.databricks.sql.transaction.tahoe.schema.InvariantViolationException$.apply(InvariantViolationException.scala:69)\n\tat com.databricks.sql.transaction.tahoe.schema.InvariantViolationException.apply(InvariantViolationException.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificUnsafeProjection.apply(Unknown Source)\n\tat com.databricks.sql.transaction.tahoe.constraints.DeltaInvariantCheckerExec.$anonfun$doExecute$3(DeltaInvariantCheckerExec.scala:90)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:91)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:437)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1715)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:444)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$20(FileFormatWriter.scala:336)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:156)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:125)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:95)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:832)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1681)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:835)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:690)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)</div>",
       "errorSummary": "InvariantViolationException: CHECK constraint validids ((ID_AUTOR > 0) AND (ID_AUTOR < 5)) violated by row with values:\n - ID_AUTOR : 5.0",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%scala\n",
    "val scrisql = \"Insert into TB_AUTOR (ID_AUTOR,NOME,SEXO,DATA_NASCIMENTO)\"+\n",
    "\" values (5,'Joao','M', '01/01/1970');\"\n",
    "spark.sql(scrisql);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2823848b-94a4-421d-adf3-193bce1c5809",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1243705193155214,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Projeto Livraria",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
